{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rh/s8rpwcgj7zd5btb07r6f891m0000gn/T/ipykernel_1450/477989729.py:2: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"DrDoS_DNS_data_1_per.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Read and concatenate all CSV files\n",
    "df = pd.read_csv(\"DrDoS_DNS_data_1_per.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5074413 entries, 0 to 5074412\n",
      "Data columns (total 88 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   Unnamed: 0                    int64  \n",
      " 1   Flow ID                       object \n",
      " 2    Source IP                    object \n",
      " 3    Source Port                  int64  \n",
      " 4    Destination IP               object \n",
      " 5    Destination Port             int64  \n",
      " 6    Protocol                     int64  \n",
      " 7    Timestamp                    object \n",
      " 8    Flow Duration                int64  \n",
      " 9    Total Fwd Packets            int64  \n",
      " 10   Total Backward Packets       int64  \n",
      " 11  Total Length of Fwd Packets   float64\n",
      " 12   Total Length of Bwd Packets  float64\n",
      " 13   Fwd Packet Length Max        float64\n",
      " 14   Fwd Packet Length Min        float64\n",
      " 15   Fwd Packet Length Mean       float64\n",
      " 16   Fwd Packet Length Std        float64\n",
      " 17  Bwd Packet Length Max         float64\n",
      " 18   Bwd Packet Length Min        float64\n",
      " 19   Bwd Packet Length Mean       float64\n",
      " 20   Bwd Packet Length Std        float64\n",
      " 21  Flow Bytes/s                  float64\n",
      " 22   Flow Packets/s               float64\n",
      " 23   Flow IAT Mean                float64\n",
      " 24   Flow IAT Std                 float64\n",
      " 25   Flow IAT Max                 float64\n",
      " 26   Flow IAT Min                 float64\n",
      " 27  Fwd IAT Total                 float64\n",
      " 28   Fwd IAT Mean                 float64\n",
      " 29   Fwd IAT Std                  float64\n",
      " 30   Fwd IAT Max                  float64\n",
      " 31   Fwd IAT Min                  float64\n",
      " 32  Bwd IAT Total                 float64\n",
      " 33   Bwd IAT Mean                 float64\n",
      " 34   Bwd IAT Std                  float64\n",
      " 35   Bwd IAT Max                  float64\n",
      " 36   Bwd IAT Min                  float64\n",
      " 37  Fwd PSH Flags                 int64  \n",
      " 38   Bwd PSH Flags                int64  \n",
      " 39   Fwd URG Flags                int64  \n",
      " 40   Bwd URG Flags                int64  \n",
      " 41   Fwd Header Length            int64  \n",
      " 42   Bwd Header Length            int64  \n",
      " 43  Fwd Packets/s                 float64\n",
      " 44   Bwd Packets/s                float64\n",
      " 45   Min Packet Length            float64\n",
      " 46   Max Packet Length            float64\n",
      " 47   Packet Length Mean           float64\n",
      " 48   Packet Length Std            float64\n",
      " 49   Packet Length Variance       float64\n",
      " 50  FIN Flag Count                int64  \n",
      " 51   SYN Flag Count               int64  \n",
      " 52   RST Flag Count               int64  \n",
      " 53   PSH Flag Count               int64  \n",
      " 54   ACK Flag Count               int64  \n",
      " 55   URG Flag Count               int64  \n",
      " 56   CWE Flag Count               int64  \n",
      " 57   ECE Flag Count               int64  \n",
      " 58   Down/Up Ratio                float64\n",
      " 59   Average Packet Size          float64\n",
      " 60   Avg Fwd Segment Size         float64\n",
      " 61   Avg Bwd Segment Size         float64\n",
      " 62   Fwd Header Length.1          int64  \n",
      " 63  Fwd Avg Bytes/Bulk            int64  \n",
      " 64   Fwd Avg Packets/Bulk         int64  \n",
      " 65   Fwd Avg Bulk Rate            int64  \n",
      " 66   Bwd Avg Bytes/Bulk           int64  \n",
      " 67   Bwd Avg Packets/Bulk         int64  \n",
      " 68  Bwd Avg Bulk Rate             int64  \n",
      " 69  Subflow Fwd Packets           int64  \n",
      " 70   Subflow Fwd Bytes            int64  \n",
      " 71   Subflow Bwd Packets          int64  \n",
      " 72   Subflow Bwd Bytes            int64  \n",
      " 73  Init_Win_bytes_forward        int64  \n",
      " 74   Init_Win_bytes_backward      int64  \n",
      " 75   act_data_pkt_fwd             int64  \n",
      " 76   min_seg_size_forward         int64  \n",
      " 77  Active Mean                   float64\n",
      " 78   Active Std                   float64\n",
      " 79   Active Max                   float64\n",
      " 80   Active Min                   float64\n",
      " 81  Idle Mean                     float64\n",
      " 82   Idle Std                     float64\n",
      " 83   Idle Max                     float64\n",
      " 84   Idle Min                     float64\n",
      " 85  SimillarHTTP                  object \n",
      " 86   Inbound                      int64  \n",
      " 87   Label                        object \n",
      "dtypes: float64(45), int64(37), object(6)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>28415</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>42680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>48549</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>48337</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>32026</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol   Flow Duration   Total Fwd Packets   Total Backward Packets  \\\n",
       "0        17           28415                  97                        0   \n",
       "1        17               2                   2                        0   \n",
       "2        17           48549                 200                        0   \n",
       "3        17           48337                 200                        0   \n",
       "4        17           32026                 200                        0   \n",
       "\n",
       "   Total Length of Fwd Packets   Total Length of Bwd Packets  \\\n",
       "0                      42680.0                           0.0   \n",
       "1                        880.0                           0.0   \n",
       "2                      88000.0                           0.0   \n",
       "3                      88000.0                           0.0   \n",
       "4                      88000.0                           0.0   \n",
       "\n",
       "    Fwd Packet Length Max   Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
       "0                   440.0                   440.0                    440.0   \n",
       "1                   440.0                   440.0                    440.0   \n",
       "2                   440.0                   440.0                    440.0   \n",
       "3                   440.0                   440.0                    440.0   \n",
       "4                   440.0                   440.0                    440.0   \n",
       "\n",
       "    Fwd Packet Length Std  ...  Active Mean   Active Std   Active Max  \\\n",
       "0                     0.0  ...          0.0          0.0          0.0   \n",
       "1                     0.0  ...          0.0          0.0          0.0   \n",
       "2                     0.0  ...          0.0          0.0          0.0   \n",
       "3                     0.0  ...          0.0          0.0          0.0   \n",
       "4                     0.0  ...          0.0          0.0          0.0   \n",
       "\n",
       "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Inbound  \\\n",
       "0          0.0        0.0        0.0        0.0        0.0         1   \n",
       "1          0.0        0.0        0.0        0.0        0.0         0   \n",
       "2          0.0        0.0        0.0        0.0        0.0         1   \n",
       "3          0.0        0.0        0.0        0.0        0.0         1   \n",
       "4          0.0        0.0        0.0        0.0        0.0         1   \n",
       "\n",
       "       Label  \n",
       "0  DrDoS_DNS  \n",
       "1  DrDoS_DNS  \n",
       "2  DrDoS_DNS  \n",
       "3  DrDoS_DNS  \n",
       "4  DrDoS_DNS  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = df.drop(columns=['Unnamed: 0', 'Flow ID', ' Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Timestamp', 'SimillarHTTP' ], axis=1)\n",
    "filtered_data.rename(columns={' Label': 'Label'}, inplace=True)\n",
    "filtered_data.rename(columns={' Protocol': 'Protocol'}, inplace=True)\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "DrDoS_DNS    5071011\n",
       "BENIGN          3402\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol\n",
       "17    5070662\n",
       "6        3369\n",
       "0         382\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.Protocol.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protocol_6\n",
       "False    5071044\n",
       "True        3369\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "df_one_hot = pd.get_dummies(filtered_data, columns=['Protocol'], prefix='Protocol')\n",
    "\n",
    "df_one_hot.Protocol_6.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data.drop('Label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5074413 entries, 0 to 5074412\n",
      "Data columns (total 79 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   Protocol                      int64  \n",
      " 1    Flow Duration                int64  \n",
      " 2    Total Fwd Packets            int64  \n",
      " 3    Total Backward Packets       int64  \n",
      " 4   Total Length of Fwd Packets   float64\n",
      " 5    Total Length of Bwd Packets  float64\n",
      " 6    Fwd Packet Length Max        float64\n",
      " 7    Fwd Packet Length Min        float64\n",
      " 8    Fwd Packet Length Mean       float64\n",
      " 9    Fwd Packet Length Std        float64\n",
      " 10  Bwd Packet Length Max         float64\n",
      " 11   Bwd Packet Length Min        float64\n",
      " 12   Bwd Packet Length Mean       float64\n",
      " 13   Bwd Packet Length Std        float64\n",
      " 14  Flow Bytes/s                  float64\n",
      " 15   Flow Packets/s               float64\n",
      " 16   Flow IAT Mean                float64\n",
      " 17   Flow IAT Std                 float64\n",
      " 18   Flow IAT Max                 float64\n",
      " 19   Flow IAT Min                 float64\n",
      " 20  Fwd IAT Total                 float64\n",
      " 21   Fwd IAT Mean                 float64\n",
      " 22   Fwd IAT Std                  float64\n",
      " 23   Fwd IAT Max                  float64\n",
      " 24   Fwd IAT Min                  float64\n",
      " 25  Bwd IAT Total                 float64\n",
      " 26   Bwd IAT Mean                 float64\n",
      " 27   Bwd IAT Std                  float64\n",
      " 28   Bwd IAT Max                  float64\n",
      " 29   Bwd IAT Min                  float64\n",
      " 30  Fwd PSH Flags                 int64  \n",
      " 31   Bwd PSH Flags                int64  \n",
      " 32   Fwd URG Flags                int64  \n",
      " 33   Bwd URG Flags                int64  \n",
      " 34   Fwd Header Length            int64  \n",
      " 35   Bwd Header Length            int64  \n",
      " 36  Fwd Packets/s                 float64\n",
      " 37   Bwd Packets/s                float64\n",
      " 38   Min Packet Length            float64\n",
      " 39   Max Packet Length            float64\n",
      " 40   Packet Length Mean           float64\n",
      " 41   Packet Length Std            float64\n",
      " 42   Packet Length Variance       float64\n",
      " 43  FIN Flag Count                int64  \n",
      " 44   SYN Flag Count               int64  \n",
      " 45   RST Flag Count               int64  \n",
      " 46   PSH Flag Count               int64  \n",
      " 47   ACK Flag Count               int64  \n",
      " 48   URG Flag Count               int64  \n",
      " 49   CWE Flag Count               int64  \n",
      " 50   ECE Flag Count               int64  \n",
      " 51   Down/Up Ratio                float64\n",
      " 52   Average Packet Size          float64\n",
      " 53   Avg Fwd Segment Size         float64\n",
      " 54   Avg Bwd Segment Size         float64\n",
      " 55   Fwd Header Length.1          int64  \n",
      " 56  Fwd Avg Bytes/Bulk            int64  \n",
      " 57   Fwd Avg Packets/Bulk         int64  \n",
      " 58   Fwd Avg Bulk Rate            int64  \n",
      " 59   Bwd Avg Bytes/Bulk           int64  \n",
      " 60   Bwd Avg Packets/Bulk         int64  \n",
      " 61  Bwd Avg Bulk Rate             int64  \n",
      " 62  Subflow Fwd Packets           int64  \n",
      " 63   Subflow Fwd Bytes            int64  \n",
      " 64   Subflow Bwd Packets          int64  \n",
      " 65   Subflow Bwd Bytes            int64  \n",
      " 66  Init_Win_bytes_forward        int64  \n",
      " 67   Init_Win_bytes_backward      int64  \n",
      " 68   act_data_pkt_fwd             int64  \n",
      " 69   min_seg_size_forward         int64  \n",
      " 70  Active Mean                   float64\n",
      " 71   Active Std                   float64\n",
      " 72   Active Max                   float64\n",
      " 73   Active Min                   float64\n",
      " 74  Idle Mean                     float64\n",
      " 75   Idle Std                     float64\n",
      " 76   Idle Max                     float64\n",
      " 77   Idle Min                     float64\n",
      " 78   Inbound                      int64  \n",
      "dtypes: float64(45), int64(34)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "X.isnull().sum()\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with infinity: ['Flow Bytes/s', ' Flow Packets/s']\n"
     ]
    }
   ],
   "source": [
    "columns_with_inf = X.columns[np.isinf(X).any(axis=0)]\n",
    "\n",
    "print(f\"Columns with infinity: {columns_with_inf.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.where(np.isinf(X), np.nan, X) \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 2.36791673e-04, 9.58590871e-04, 0.00000000e+00,\n",
       "        2.79567909e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.10198227e-04, 8.53412672e-04,\n",
       "        6.56936670e-06, 8.52438172e-06, 2.99820490e-05, 2.21945875e-08,\n",
       "        2.36791888e-04, 6.56936670e-06, 8.52438172e-06, 2.99820490e-05,\n",
       "        2.21945875e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        8.53422488e-04, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66903429e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.58590871e-04, 2.79567909e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.90362879e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.66666671e-08, 9.98532158e-06, 0.00000000e+00,\n",
       "        5.76428678e-05, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.49456522e-01, 2.49999993e-01,\n",
       "        4.43891750e-08, 0.00000000e+00, 1.66752219e-08, 4.43891750e-08,\n",
       "        1.66666822e-08, 4.43891750e-08, 0.00000000e+00, 1.66752219e-08,\n",
       "        4.43891750e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        2.50000000e-01, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.47800499e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.98532158e-06, 5.76428678e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.98294666e-04, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 4.04575010e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.15693513e-04, 1.02987752e-03,\n",
       "        5.41469863e-06, 9.83704017e-06, 4.51731761e-05, 2.21945875e-08,\n",
       "        4.04575378e-04, 5.41469863e-06, 9.83704017e-06, 4.51731761e-05,\n",
       "        2.21945875e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.02988733e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.02808343e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.18393867e-04, 1.03439447e-03,\n",
       "        5.39105415e-06, 8.25779694e-06, 2.78226077e-05, 2.21945875e-08,\n",
       "        4.02808709e-04, 5.39105415e-06, 8.25779694e-06, 2.78226077e-05,\n",
       "        2.21945875e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.03440429e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.66883340e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.33344918e-04, 1.56122169e-03,\n",
       "        3.57187869e-06, 3.35032476e-06, 1.03052871e-05, 0.00000000e+00,\n",
       "        2.66883582e-04, 3.57187869e-06, 3.35032476e-06, 1.03052871e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.56123150e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.87241676e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.43252584e-04, 1.07597633e-03,\n",
       "        5.18271501e-06, 8.52426592e-06, 3.02071645e-05, 0.00000000e+00,\n",
       "        3.87242028e-04, 5.18271501e-06, 8.52426592e-06, 3.02071645e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.07598614e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.60008340e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.58023921e-04, 1.60250293e-03,\n",
       "        3.47986595e-06, 3.15735896e-06, 7.33709763e-06, 0.00000000e+00,\n",
       "        2.60008576e-04, 3.47986595e-06, 3.15735896e-06, 7.33709763e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.60251274e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.20441677e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.92458414e-04, 9.91011532e-04,\n",
       "        5.62705288e-06, 1.12929265e-05, 6.37743861e-05, 2.21945875e-08,\n",
       "        4.20442059e-04, 5.62705288e-06, 1.12929265e-05, 6.37743861e-05,\n",
       "        2.21945875e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        9.91021347e-04, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.58400006e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.63986853e-04, 1.61247729e-03,\n",
       "        3.45834055e-06, 3.05461071e-06, 7.87070473e-06, 0.00000000e+00,\n",
       "        2.58400241e-04, 3.45834055e-06, 3.05461071e-06, 7.87070473e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.61248710e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 2.51191673e-04, 1.98707899e-03, 0.00000000e+00,\n",
       "        5.76428678e-03, 0.00000000e+00, 1.36986301e-02, 2.17821782e-01,\n",
       "        1.45922920e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.91649947e-04, 1.65875010e-03,\n",
       "        3.36186659e-06, 3.02958646e-06, 7.87904234e-06, 0.00000000e+00,\n",
       "        2.51191901e-04, 3.36186659e-06, 3.02958646e-06, 7.87904234e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.99999383e-01, 9.99930711e-01,\n",
       "        1.65875991e-03, 0.00000000e+00, 2.98913043e-01, 1.31030375e-02,\n",
       "        1.65272789e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.66026334e-01, 1.45922920e-01, 0.00000000e+00, 9.99999383e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.98707899e-03, 5.76428678e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.94606385e-02, 9.99998948e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minMaxScaler = MinMaxScaler()\n",
    "X_normalized = minMaxScaler.fit_transform(X)\n",
    "X_normalized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'BENIGN': 1, 'DrDoS_DNS': 2}\n",
    "filtered_data['Label'] = filtered_data['Label'].map(label_mapping)\n",
    "y = filtered_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y, test_size=0.4, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [    681 1014202]\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(y_valid, return_counts=True)\n",
    "print(values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float64)\n",
    "        self.y = torch.tensor(y.values if isinstance(y, pd.Series) else y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = myDataset(X_train, y_train)\n",
    "valid_dataset = myDataset(X_valid, y_valid)\n",
    "test_dataset = myDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 79])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes=2): # numclass 2 because classified benign and non benigm=n, hidden size = jumlah neuron, # input size = jumlah feature\n",
    "        super(FFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # layer 1\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # layer 2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = 2\n",
    "hidden_size = 32\n",
    "model = FFNN(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/go/src/github.com/masatrio/thesis-ddos/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/go/src/github.com/masatrio/thesis-ddos/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[95], line 9\u001b[0m, in \u001b[0;36mFFNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#x = self.relu(self.fc2(x))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# x = self.fc3(x)\u001b[39;00m\n",
      "File \u001b[0;32m~/go/src/github.com/masatrio/thesis-ddos/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/go/src/github.com/masatrio/thesis-ddos/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/go/src/github.com/masatrio/thesis-ddos/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f'runs/FFNN_{current_time}'\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100 * np.mean(np.array(all_labels) == np.array(all_predictions))\n",
    "    train_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    # Log training metrics\n",
    "    writer.add_scalar('Loss/Train', avg_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
    "    writer.add_scalar('F1 Score/Train', train_f1, epoch)\n",
    "    \n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * np.mean(np.array(all_labels) == np.array(all_predictions))\n",
    "        val_f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        # Log validation metrics\n",
    "        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "        writer.add_scalar('F1 Score/Validation', val_f1, epoch)\n",
    "    \n",
    "    # Log learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Learning Rate', current_lr, epoch)\n",
    "    \n",
    "    # if epoch % 10 == 0:\n",
    "    print(f'Epoch [{epoch}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}, '\n",
    "            f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Val F1: {val_f1:.4f}, LR: {current_lr:.6f}')\n",
    "    early_stopping(avg_val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "#model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
